{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29236f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc41f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Projects\\Academic Score Prediction Model\\ResearchInformation3.csv\")\n",
    "\n",
    "x = df.iloc[:, 4:13].values\n",
    "print(x.shape)\n",
    "y = df.iloc[:, -1].values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "y = df.iloc[: , -1].values\n",
    "\n",
    "encoder_Income = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "trasnformed_Income = encoder_Income.fit_transform(df.loc[:, [\"Income\"]])\n",
    "\n",
    "\n",
    "encoder_nominal = OrdinalEncoder()\n",
    "transformed_nominal = encoder_nominal.fit_transform(df[[\"Hometown\", \"Job\", \"Extra\"]])\n",
    "\n",
    "\n",
    "categorical_columns = [\"Preparation\", \"Gaming\"]\n",
    "time_categories = [[\"0-1 Hour\", \"2-3 Hours\", \"More than 3 Hours\"]]\n",
    "trasnformed_categories = []\n",
    "for col in categorical_columns:\n",
    "    encoder_columns = OrdinalEncoder(categories=time_categories)\n",
    "    trasnformed_categories.append(encoder_columns.fit_transform(df[[col]]))\n",
    "\n",
    "\n",
    "attendance_categories = [[\"Below 40%\", \"40%-59%\",\"60%-79%\", \"80%-100%\"]]\n",
    "encoder_Attendance = OrdinalEncoder(categories=attendance_categories)\n",
    "trasnformed_Attendance = encoder_Attendance.fit_transform(df.loc[:, [\"Attendance\"]])\n",
    "\n",
    "\n",
    "numeric_features = df[[\"Computer\", \"Last\"]].values\n",
    "\n",
    "\n",
    "x = np.concatenate([trasnformed_Income, transformed_nominal, trasnformed_Attendance, *trasnformed_categories, numeric_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92666b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, max_depth=3),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, max_depth=2, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    train_score = model.score(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {} \n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(x_test)\n",
    "    predictions[name] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "results = []\n",
    "for name, y_pred in predictions.items():\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"R2\": r2_score(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = np.round(pd.DataFrame(results), 2)\n",
    "print(f\"\\nPerformance Comparison:\\n {results_df}\")\n",
    "\n",
    "the_best_model = results_df.loc[results_df['R2'].idxmax(), 'Model']\n",
    "print(f\"\\nthe best model: {the_best_model}\")\n",
    "\n",
    "the_worst_model = results_df.loc[results_df['R2'].idxmin(), 'Model']\n",
    "print(f\"the worst model: {the_worst_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e674af",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['R2', 'MAE', 'MSE','RMSE']\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.bar(results_df['Model'], results_df[metric], color='skyblue')\n",
    "    plt.title(f'{metric} Comparison of Models')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Models')\n",
    "    for i, val in enumerate(results_df[metric]):\n",
    "        plt.text(i, val, f'{val:.2f}', ha='center')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
